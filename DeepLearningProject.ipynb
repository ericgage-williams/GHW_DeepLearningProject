{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KkjrVAipxxp_"
      },
      "source": [
        "# Understanding the Yolo Algorithm and Fine-Tuning It\n",
        "____\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDSpEHVpywxK"
      },
      "source": [
        "# Overview of Yolo Algorithm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k9DZRiUi3wAX"
      },
      "source": [
        "The YOLO algorithm is designed to preform object detection and image classification. Usually, detection and classification are often two separate models which take two passes, however, yolo combines the two in one pass which is why it's named you only look one. This allows for quick detection and the ability to be used in real time applications.  The following output looks like this:\n",
        "\n",
        "<img src=\"cover.png\" width=\"400\" height=\"300\">\n",
        "\n",
        "Yolo does object detection and classification in one pass by dividing the image into an SXS Matrix like the image below:\n",
        "\n",
        "<img src=\"SXS.png\" width=\"300\" height=\"300\">\n",
        "\n",
        "Then for each cell two categories of features is created, the first, is on the object detection boxes and the second is classification of each SXS square. The Object Detction is done in the following way. For each rectangle in SXS we take a finite amount of bounding boxes. For example if we take two boxes per rectange we would have to vectors with the following data:\n",
        "\n",
        "                                    [x, y, sqrt(W), sqrt(H), C]\n",
        "\n",
        "X, Y are the center coordinates of the bounding box, W and H are the width and height, and C which is a confidence score representing the models confidence that an object actually exists in the bounding box.\n",
        "Additionally, we have a tensor with the following data \n",
        "\n",
        "                                    [P(c1), P(c2), ... P(cn)]\n",
        "\n",
        "This represents what is the probability that what is in the SXS cell is a given classification. So for each grid, we eventually build a (Bx5+n) matrix where B is the number of bounding boxes and n is the number of classifications in the model. We repeat this process for each cell in the SXS grid until we have a final feature matrix. \n",
        "\n",
        "We then use a loss function, which will be explained later in this markdown to compute both how well the bounding boxes are predicting object, how well the model is classified, and how well the combination is doing. \n",
        "\n",
        "Because we gather all the data in one pass, yolo can run quite fast. The newest versions run at 45 frames per second while optimized versions can process at 150 frames per second with 25 milliseconds of latency. The best alternative RCNN's most opitmized version runs at about max 17 frames per second. \n",
        "\n",
        "In this tutorial, we will teach you how to implement YoloV1, we will then shop how to pull the YoloV8 pre trained off the web and opotimize it for your preferred use. Below are code snipets of indepth walk through of impleting the YoloV1 model...We will disscuss data engineering, the loss function, and then tying it all together in an CNN.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooMFDAcIySAC"
      },
      "source": [
        "# Data Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by importing the necessary packages. Most of the packages we will use are torch modules. We will also use some scikit-image modules, as well as an xml module and a counter from Collections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import skimage\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as FT\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "seed = 123\n",
        "import xml.etree.ElementTree as ET\n",
        "torch.manual_seed(seed)\n",
        "from collections import Counter"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we set our train and test directiories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_dir = './archive/train'\n",
        "test_dir = './archive/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we need to build out dataframes for our training and test images. We will need to annotate the images for training purposes. We do this by looping through and creating a new series of `.xml` files of the same name as their `.jpg` counterparts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Jyt12EGz0ryJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df Sample:\n",
            "            images         annots\n",
            "217  orange_56.jpg  orange_56.xml\n",
            "\n",
            "test_df Sample:\n",
            "     test_images   test_annots\n",
            "10  apple_87.jpg  apple_87.xml\n"
          ]
        }
      ],
      "source": [
        "### BUILD TRAINING DF\n",
        "images = [image for image in sorted(os.listdir(files_dir)) if image[-4:]=='.jpg']\n",
        "annots = []\n",
        "# build annotations\n",
        "for image in images:\n",
        "    annot = image[:-4] + '.xml'\n",
        "    annots.append(annot)\n",
        "    \n",
        "images = pd.Series(images, name='images')\n",
        "annots = pd.Series(annots, name='annots')\n",
        "df = pd.concat([images, annots], axis=1)  # Nx2 df where N is num training pictures\n",
        "df = pd.DataFrame(df)  # training df\n",
        "\n",
        "print(\"df Sample:\")\n",
        "print(df.sample(1))\n",
        "print()\n",
        "\n",
        "### BUILD TEST DF\n",
        "test_images = [image for image in sorted(os.listdir(test_dir))\n",
        "                        if image[-4:]=='.jpg']\n",
        "\n",
        "test_annots = []\n",
        "# build test annotations\n",
        "for image in test_images:\n",
        "    annot = image[:-4] + '.xml'\n",
        "    test_annots.append(annot)\n",
        "\n",
        "test_images = pd.Series(test_images, name='test_images')\n",
        "test_annots = pd.Series(test_annots, name='test_annots')\n",
        "test_df = pd.concat([test_images, test_annots], axis=1)  # Nx2 df where N is num test pictures\n",
        "test_df = pd.DataFrame(test_df)  # test df\n",
        "\n",
        "print(\"test_df Sample:\")\n",
        "print(test_df.sample(1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next step is to build our dataset that we'll use for testing. We will use `df` and the `files_dir` to build our `torch` dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2lCx1bl40AZH"
      },
      "outputs": [],
      "source": [
        "class FruitImagesDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df=df, files_dir=files_dir, S=7, B=2, C=3, transform=None):\n",
        "        self.annotations = df  # use annotated df we made for the Dataset annotations\n",
        "        self.files_dir = files_dir\n",
        "        self.transform = transform  # not using a transform\n",
        "        self.S = S  # split size\n",
        "        self.B = B  # num boxes\n",
        "        self.C = C  # num classes\n",
        "\n",
        "    # Size of the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.annotations) \n",
        "\n",
        "    # Get item from an index\n",
        "    def __getitem__(self, index):\n",
        "        # get full path\n",
        "        label_path = os.path.join(self.files_dir, self.annotations.iloc[index, 1])\n",
        "        boxes = []\n",
        "        tree = ET.parse(label_path)\n",
        "        root = tree.getroot()\n",
        "        \n",
        "        class_dictionary = {'apple':0, 'banana':1, 'orange':2}\n",
        "\n",
        "        if(int(root.find('size').find('height').text) == 0):\n",
        "            filename = root.find('filename').text\n",
        "            img = Image.open(self.files_dir + '/' + filename)\n",
        "            img_width, img_height = img.size\n",
        "            \n",
        "            for member in root.findall('object'):\n",
        "            \n",
        "                klass = member.find('name').text\n",
        "                klass = class_dictionary[klass]\n",
        "            \n",
        "                # bounding box\n",
        "                xmin = int(member.find('bndbox').find('xmin').text)\n",
        "                xmax = int(member.find('bndbox').find('xmax').text)\n",
        "            \n",
        "                ymin = int(member.find('bndbox').find('ymin').text)\n",
        "                ymax = int(member.find('bndbox').find('ymax').text)\n",
        "                \n",
        "                centerx = ((xmax + xmin) / 2) / img_width\n",
        "                centery = ((ymax + ymin) / 2) / img_height\n",
        "                boxwidth = (xmax - xmin) / img_width\n",
        "                boxheight = (ymax - ymin) / img_height\n",
        "            \n",
        "            \n",
        "                boxes.append([klass, centerx, centery, boxwidth, boxheight])\n",
        "            \n",
        "        elif(int(root.find('size').find('height').text) != 0):\n",
        "            \n",
        "            for member in root.findall('object'):\n",
        "            \n",
        "                klass = member.find('name').text\n",
        "                klass = class_dictionary[klass]\n",
        "            \n",
        "                                # bounding box\n",
        "                xmin = int(member.find('bndbox').find('xmin').text)\n",
        "                xmax = int(member.find('bndbox').find('xmax').text)\n",
        "                img_width = int(root.find('size').find('width').text)\n",
        "            \n",
        "                ymin = int(member.find('bndbox').find('ymin').text)\n",
        "                ymax = int(member.find('bndbox').find('ymax').text)\n",
        "                img_height = int(root.find('size').find('height').text)\n",
        "                \n",
        "                centerx = ((xmax + xmin) / 2) / img_width\n",
        "                centery = ((ymax + ymin) / 2) / img_height\n",
        "                boxwidth = (xmax - xmin) / img_width\n",
        "                boxheight = (ymax - ymin) / img_height\n",
        "            \n",
        "            \n",
        "                boxes.append([klass, centerx, centery, boxwidth, boxheight])\n",
        "\n",
        "                \n",
        "        boxes = torch.tensor(boxes)\n",
        "        img_path = os.path.join(self.files_dir, self.annotations.iloc[index, 0])\n",
        "        image = Image.open(img_path)\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            # image = self.transform(image)\n",
        "            image, boxes = self.transform(image, boxes)\n",
        "\n",
        "        # Convert To Cells\n",
        "        label_matrix = torch.zeros((self.S, self.S, self.C + 5 * self.B))\n",
        "        for box in boxes:\n",
        "            class_label, x, y, width, height = box.tolist()\n",
        "            class_label = int(class_label)\n",
        "\n",
        "            # i,j represents the cell row and cell column\n",
        "            i, j = int(self.S * y), int(self.S * x)\n",
        "            x_cell, y_cell = self.S * x - j, self.S * y - i\n",
        "\n",
        "            \"\"\"\n",
        "            Calculating the width and height of cell of bounding box,\n",
        "            relative to the cell is done by the following, with\n",
        "            width as the example:\n",
        "            \n",
        "            width_pixels = (width*self.image_width)\n",
        "            cell_pixels = (self.image_width)\n",
        "            \n",
        "            Then to find the width relative to the cell is simply:\n",
        "            width_pixels/cell_pixels, simplification leads to the\n",
        "            formulas below.\n",
        "            \"\"\"\n",
        "            width_cell, height_cell = (\n",
        "                width * self.S,\n",
        "                height * self.S,\n",
        "            )\n",
        "\n",
        "            # If no object already found for specific cell i,j\n",
        "            # Note: This means we restrict to ONE object\n",
        "            # per cell!\n",
        "#             print(i, j)\n",
        "            if label_matrix[i, j, self.C] == 0:\n",
        "                # Set that there exists an object\n",
        "                label_matrix[i, j, self.C] = 1\n",
        "\n",
        "                # Box coordinates\n",
        "                box_coordinates = torch.tensor(\n",
        "                    [x_cell, y_cell, width_cell, height_cell]\n",
        "                )\n",
        "\n",
        "                label_matrix[i, j, 4:8] = box_coordinates\n",
        "\n",
        "                # Set one hot encoding for class_label\n",
        "                label_matrix[i, j, class_label] = 1\n",
        "\n",
        "        return image, label_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0tDPS_2zMvw"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "grid_size: the original image is divided into a grid with length grid_size  \n",
        "num_boxes: number of bounding boxes to be predicted in each grid cell  \n",
        "num_classes: number of classes an object can be identified as  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Intersection over Union Utility Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The intersection over Union metric is used to determine how well the predicted box matches the annotated box label. The function is essentially a ratio where the numerator is the overlap between the predictions and the denominator is the total area of the predictions. As a result, a perfect match would have an IoU score of 1, and worse predictions would have a score less than 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intersection_over_union(boxes_preds, boxes_labels, box_format='midpoint'):\n",
        "    \"\"\"\n",
        "    Calculates intersection over union\n",
        "    \n",
        "    Parameters:\n",
        "        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
        "        boxes_labels (tensor): Correct labels of Bounding Boxes (BATCH_SIZE, 4)\n",
        "        box_format (str): midpoint/corners, if boxes are (x,y,w,h) or (x1,y1,x2,y2) respectively.\n",
        "    \n",
        "    Returns:\n",
        "        tensor: Intersection over union for all examples\n",
        "    \"\"\"\n",
        "    # boxes_preds shape is (N, 4) where N is the number of bboxes\n",
        "    #boxes_labels shape is (n, 4)\n",
        "    \n",
        "    if box_format == 'midpoint':\n",
        "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
        "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
        "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
        "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
        "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
        "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
        "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
        "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
        "        \n",
        "    if box_format == 'corners':\n",
        "        box1_x1 = boxes_preds[..., 0:1]\n",
        "        box1_y1 = boxes_preds[..., 1:2]\n",
        "        box1_x2 = boxes_preds[..., 2:3]\n",
        "        box1_y2 = boxes_preds[..., 3:4] # Output tensor should be (N, 1). If we only use 3, we go to (N)\n",
        "        box2_x1 = boxes_labels[..., 0:1]\n",
        "        box2_y1 = boxes_labels[..., 1:2]\n",
        "        box2_x2 = boxes_labels[..., 2:3]\n",
        "        box2_y2 = boxes_labels[..., 3:4]\n",
        "    \n",
        "    x1 = torch.max(box1_x1, box2_x1)\n",
        "    y1 = torch.max(box1_y1, box2_y1)\n",
        "    x2 = torch.min(box1_x2, box2_x2)\n",
        "    y2 = torch.min(box1_y2, box2_y2)\n",
        "    \n",
        "    #.clamp(0) is for the case when they don't intersect. Since when they don't intersect, one of these will be negative so that should become 0\n",
        "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
        "    \n",
        "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
        "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
        "    \n",
        "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss Function for Box Coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_fn_box_coordinates(predictions, target, num_classes=3):\n",
        "    \n",
        "    ## First calculate IoUs for the two bounding box predictions\n",
        "    iou_b1 = intersection_over_union(predictions[..., num_classes + 1:num_classes + 5], target[..., num_classes + 1:num_classes + 5])\n",
        "    iou_b2 = intersection_over_union(predictions[..., num_classes + 6:num_classes + 10], target[..., num_classes + 1:num_classes + 5])\n",
        "    ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n",
        "\n",
        "    iou_maxes, bestbox = torch.max(ious, dim=0)\n",
        "    exists_box = target[..., num_classes].unsqueeze(3)\n",
        "\n",
        "    box_predictions = exists_box * (\n",
        "            (\n",
        "                bestbox * predictions[..., num_classes + 6:num_classes + 10]\n",
        "                + (1 - bestbox) * predictions[..., num_classes + 1:num_classes + 5]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    box_targets = exists_box * target[..., num_classes + 1:num_classes + 5]\n",
        "\n",
        "    # Take sqrt of width, height of boxes to ensure that\n",
        "    box_predictions[..., 2:4] = torch.sign(box_predictions[..., 2:4]) * torch.sqrt(\n",
        "        torch.abs(box_predictions[..., 2:4] + 1e-6)\n",
        "    )\n",
        "    box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n",
        "\n",
        "    mse = nn.MSELoss(reduction=\"sum\")\n",
        "    return mse(\n",
        "            torch.flatten(box_predictions, end_dim=-2),\n",
        "            torch.flatten(box_targets, end_dim=-2),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss Function for Object Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_fn_object_loss(predictions, target, num_classes=3):\n",
        "\n",
        "    ## First calculate IoUs for the two bounding box predictions\n",
        "    iou_b1 = intersection_over_union(predictions[..., num_classes + 1:num_classes + 5], target[..., num_classes + 1:num_classes + 5])\n",
        "    iou_b2 = intersection_over_union(predictions[..., num_classes + 6:num_classes + 10], target[..., num_classes + 1:num_classes + 5])\n",
        "    ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n",
        "\n",
        "    iou_maxes, bestbox = torch.max(ious, dim=0)\n",
        "    exists_box = target[..., num_classes].unsqueeze(3)\n",
        "\n",
        "    pred_box = (\n",
        "            bestbox * predictions[..., num_classes + 5:num_classes + 6] + (1 - bestbox) * predictions[..., num_classes:num_classes + 1]\n",
        "        )\n",
        "\n",
        "    mse = nn.MSELoss(reduction=\"sum\")\n",
        "    return mse(\n",
        "            torch.flatten(exists_box * pred_box),\n",
        "            torch.flatten(exists_box * target[..., num_classes:num_classes + 1]),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss Function for No Object Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_fn_no_object_loss(predictions, target, num_classes=3):\n",
        "    exists_box = target[..., num_classes].unsqueeze(3)\n",
        "\n",
        "    mse = nn.MSELoss(reduction=\"sum\")\n",
        "\n",
        "    # two MSEs because summing first predicted box for each grid cell and then second predicted box\n",
        "    no_object_loss = mse(\n",
        "            torch.flatten((1 - exists_box) * predictions[..., num_classes:num_classes + 1], start_dim=1),\n",
        "            torch.flatten((1 - exists_box) * target[..., num_classes:num_classes + 1], start_dim=1),\n",
        "        )\n",
        "\n",
        "    return no_object_loss + mse(\n",
        "            torch.flatten((1 - exists_box) * predictions[..., num_classes + 5:num_classes + 6], start_dim=1),\n",
        "            torch.flatten((1 - exists_box) * target[..., num_classes:num_classes + 1], start_dim=1)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss Function for Class Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_fn_class_loss(predictions, target, num_classes=3):\n",
        "\n",
        "    exists_box = target[..., num_classes].unsqueeze(3)\n",
        "\n",
        "    mse = nn.MSELoss(reduction=\"sum\")\n",
        "    return mse(\n",
        "            torch.flatten(exists_box * predictions[..., :num_classes], end_dim=-2,),\n",
        "            torch.flatten(exists_box * target[..., :num_classes], end_dim=-2,),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Total Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "class YoloLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Calculate the loss for yolo (v1) model\n",
        "    The only reason this is it's own module is to store incremenential losses\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(YoloLoss, self).__init__()\n",
        "        self.box_coordinate_losses = []\n",
        "        self.object_losses = []\n",
        "        self.no_object_losses = []\n",
        "        self.class_losses = []\n",
        "\n",
        "    def forward(self, predictions, target, grid_size=7, num_boxes=2, num_classes=3, lambda_noobj=0.5, lambda_coord=5):\n",
        "        predictions = predictions.reshape(-1, grid_size, grid_size, num_classes + num_boxes * 5)\n",
        "\n",
        "        box_coordinate_loss = lambda_coord * loss_fn_box_coordinates(predictions, target, num_classes)\n",
        "        object_loss = loss_fn_object_loss(predictions, target, num_classes)\n",
        "        no_object_loss = lambda_noobj * loss_fn_no_object_loss(predictions, target, num_classes)\n",
        "        class_loss = loss_fn_class_loss(predictions, target, num_classes)\n",
        "        \n",
        "        self.box_coordinate_losses.append(box_coordinate_loss)\n",
        "        self.object_losses.append(object_loss)\n",
        "        self.no_object_losses.append(no_object_loss)\n",
        "        self.class_losses.append(class_loss)\n",
        "        \n",
        "        return (\n",
        "                box_coordinate_loss\n",
        "                + object_loss\n",
        "                + no_object_loss\n",
        "                + class_loss\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrrm5h8ezntr"
      },
      "source": [
        "# CNN Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each CNN layer is very standard to what we've learned in class.  \n",
        "1) There is first have a 2d Convolutional layer.  \n",
        "2) That output gets fed through a 2d normalizer to prevent overfitting  \n",
        "3) That output is passed through a leaky ReLU activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(CNNBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.leakyrelu(self.batchnorm(self.conv(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Architecture Comes Directly From the Paper"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"./architecture.png\" width=\"800\" height=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As can be seen from the image pulled from the paper, the architecture defined below comes directly from the paper. The only difference is the last two layers (labeled as 4096 and 7x7x30) are defined later as they are not part of the convolutional architecture but are the \"decoder\" for the network defined in the fully connected layers network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_conv_layers(in_channels):\n",
        "        layers = [CNNBlock(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
        "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                  CNNBlock(64, 192, kernel_size=3, stride=1, padding=1),\n",
        "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                  CNNBlock(192, 128, kernel_size=1, stride=1, padding=0),\n",
        "                  CNNBlock(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                  CNNBlock(256, 256, kernel_size=1, stride=1, padding=0),\n",
        "                  CNNBlock(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                  CNNBlock(512, 256, kernel_size=1, stride=1, padding=0),\n",
        "                  CNNBlock(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                  CNNBlock(512, 256, kernel_size=1, stride=1, padding=0),\n",
        "                  CNNBlock(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                  CNNBlock(512, 256, kernel_size=1, stride=1, padding=0),\n",
        "                  CNNBlock(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                  CNNBlock(512, 256, kernel_size=1, stride=1, padding=0),\n",
        "                  CNNBlock(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                  CNNBlock(512, 512, kernel_size=1, stride=1, padding=0),\n",
        "                  CNNBlock(512, 1024, kernel_size=3, stride=1, padding=1),\n",
        "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                  CNNBlock(1024, 512, kernel_size=1, stride=1, padding=0),\n",
        "                  CNNBlock(512, 1024, kernel_size=3, stride=1, padding=1),\n",
        "                  CNNBlock(1024, 512, kernel_size=1, stride=1, padding=0),\n",
        "                  CNNBlock(512, 1024, kernel_size=3, stride=1, padding=1),\n",
        "                  CNNBlock(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
        "                  CNNBlock(1024, 1024, kernel_size=3, stride=2, padding=1),\n",
        "                  CNNBlock(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
        "                  CNNBlock(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
        "                  ]\n",
        "                    \n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The decoder is a feed forward network that inputs a vector of features and returns a flattened output vector. As described in the paper, the fully connected layer network consists of a linear layer, dropout layer, leaky ReLU activation function, and finally another linear layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_fcs(split_size, num_boxes, num_classes):\n",
        "    S, B, C = split_size, num_boxes, num_classes\n",
        "    return nn.Sequential(nn.Flatten(), nn.Linear(1024 * S * S, 496), nn.Dropout(0.0), nn.LeakyReLU(0.1), nn.Linear(496, S * S * (C + B * 5)))\n",
        "    #Original paper uses nn.Linear(1024 * S * S, 4096) not 496. Also the last layer will be reshaped to (S, S, 13) where C+B*5 = 13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### YoloV1 Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jOu5fxH00vj1"
      },
      "outputs": [],
      "source": [
        "class YoloV1(nn.Module):\n",
        "    def __init__(self, in_channels=3, **kwargs):\n",
        "        super(YoloV1, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.darknet = create_conv_layers(self.in_channels)\n",
        "        self.fcs = create_fcs(**kwargs)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.darknet(x)\n",
        "        return self.fcs(torch.flatten(x, start_dim=1))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C7o4JDjVzvUo"
      },
      "source": [
        "# Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Three More Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def non_max_suppression(bboxes, iou_threshold, threshold, box_format=\"corners\"):\n",
        "    \"\"\"\n",
        "    Does Non Max Suppression given bboxes\n",
        "    Parameters:\n",
        "        bboxes (list): list of lists containing all bboxes with each bboxes\n",
        "        specified as [class_pred, prob_score, x1, y1, x2, y2]\n",
        "        iou_threshold (float): threshold where predicted bboxes is correct\n",
        "        threshold (float): threshold to remove predicted bboxes (independent of IoU) \n",
        "        box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n",
        "    Returns:\n",
        "        list: bboxes after performing NMS given a specific IoU threshold\n",
        "    \"\"\"\n",
        "\n",
        "    assert type(bboxes) == list\n",
        "\n",
        "    bboxes = [box for box in bboxes if box[1] > threshold]\n",
        "    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
        "    bboxes_after_nms = []\n",
        "\n",
        "    while bboxes:\n",
        "        chosen_box = bboxes.pop(0)\n",
        "\n",
        "        bboxes = [\n",
        "            box\n",
        "            for box in bboxes\n",
        "            if box[0] != chosen_box[0]\n",
        "            or intersection_over_union(\n",
        "                torch.tensor(chosen_box[2:]),\n",
        "                torch.tensor(box[2:]),\n",
        "                box_format=box_format,\n",
        "            )\n",
        "            < iou_threshold\n",
        "        ]\n",
        "\n",
        "        bboxes_after_nms.append(chosen_box)\n",
        "\n",
        "    return bboxes_after_nms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_average_precision(\n",
        "    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=20\n",
        "):\n",
        "    \"\"\"\n",
        "    Calculates mean average precision \n",
        "    Parameters:\n",
        "        pred_boxes (list): list of lists containing all bboxes with each bboxes\n",
        "        specified as [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n",
        "        true_boxes (list): Similar as pred_boxes except all the correct ones \n",
        "        iou_threshold (float): threshold where predicted bboxes is correct\n",
        "        box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n",
        "        num_classes (int): number of classes\n",
        "    Returns:\n",
        "        float: mAP value across all classes given a specific IoU threshold \n",
        "    \"\"\"\n",
        "\n",
        "    # list storing all AP for respective classes\n",
        "    average_precisions = []\n",
        "\n",
        "    # used for numerical stability later on\n",
        "    epsilon = 1e-6\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        detections = []\n",
        "        ground_truths = []\n",
        "\n",
        "        # Go through all predictions and targets,\n",
        "        # and only add the ones that belong to the\n",
        "        # current class c\n",
        "        for detection in pred_boxes:\n",
        "            if detection[1] == c:\n",
        "                detections.append(detection)\n",
        "\n",
        "        for true_box in true_boxes:\n",
        "            if true_box[1] == c:\n",
        "                ground_truths.append(true_box)\n",
        "\n",
        "        # find the amount of bboxes for each training example\n",
        "        # Counter here finds how many ground truth bboxes we get\n",
        "        # for each training example, so let's say img 0 has 3,\n",
        "        # img 1 has 5 then we will obtain a dictionary with:\n",
        "        # amount_bboxes = {0:3, 1:5}\n",
        "        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
        "\n",
        "        # We then go through each key, val in this dictionary\n",
        "        # and convert to the following (w.r.t same example):\n",
        "        # ammount_bboxes = {0:torch.tensor[0,0,0], 1:torch.tensor[0,0,0,0,0]}\n",
        "        for key, val in amount_bboxes.items():\n",
        "            amount_bboxes[key] = torch.zeros(val)\n",
        "\n",
        "        # sort by box probabilities which is index 2\n",
        "        detections.sort(key=lambda x: x[2], reverse=True)\n",
        "        TP = torch.zeros((len(detections)))\n",
        "        FP = torch.zeros((len(detections)))\n",
        "        total_true_bboxes = len(ground_truths)\n",
        "        \n",
        "        # If none exists for this class then we can safely skip\n",
        "        if total_true_bboxes == 0:\n",
        "            continue\n",
        "\n",
        "        for detection_idx, detection in enumerate(detections):\n",
        "            # Only take out the ground_truths that have the same\n",
        "            # training idx as detection\n",
        "            ground_truth_img = [\n",
        "                bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
        "            ]\n",
        "\n",
        "            num_gts = len(ground_truth_img)\n",
        "            best_iou = 0\n",
        "\n",
        "            for idx, gt in enumerate(ground_truth_img):\n",
        "                iou = intersection_over_union(\n",
        "                    torch.tensor(detection[3:]),\n",
        "                    torch.tensor(gt[3:]),\n",
        "                    box_format=box_format,\n",
        "                )\n",
        "\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_gt_idx = idx\n",
        "\n",
        "            if best_iou > iou_threshold:\n",
        "                # only detect ground truth detection once\n",
        "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
        "                    # true positive and add this bounding box to seen\n",
        "                    TP[detection_idx] = 1\n",
        "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
        "                else:\n",
        "                    FP[detection_idx] = 1\n",
        "\n",
        "            # if IOU is lower then the detection is a false positive\n",
        "            else:\n",
        "                FP[detection_idx] = 1\n",
        "\n",
        "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
        "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
        "        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
        "        precisions = torch.divide(TP_cumsum, (TP_cumsum + FP_cumsum + epsilon))\n",
        "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
        "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
        "        # torch.trapz for numerical integration\n",
        "        average_precisions.append(torch.trapz(precisions, recalls))\n",
        "\n",
        "    return sum(average_precisions) / len(average_precisions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_bboxes(\n",
        "    loader,\n",
        "    model,\n",
        "    device,\n",
        "    iou_threshold,\n",
        "    threshold,\n",
        "    pred_format=\"cells\",\n",
        "    box_format=\"midpoint\",\n",
        "):\n",
        "    all_pred_boxes = []\n",
        "    all_true_boxes = []\n",
        "\n",
        "    # make sure model is in eval before get bboxes\n",
        "    model.eval()\n",
        "    train_idx = 0\n",
        "\n",
        "    for batch_idx, (x, labels) in enumerate(loader):\n",
        "        x = x.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions = model(x)\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        true_bboxes = cellboxes_to_boxes(labels)\n",
        "        bboxes = cellboxes_to_boxes(predictions)\n",
        "\n",
        "        for idx in range(batch_size):\n",
        "            nms_boxes = non_max_suppression(\n",
        "                bboxes[idx],\n",
        "                iou_threshold=iou_threshold,\n",
        "                threshold=threshold,\n",
        "                box_format=box_format,\n",
        "            )\n",
        "\n",
        "\n",
        "            #if batch_idx == 0 and idx == 0:\n",
        "            #    plot_image(x[idx].permute(1,2,0).to(\"cpu\"), nms_boxes)\n",
        "            #    print(nms_boxes)\n",
        "\n",
        "            for nms_box in nms_boxes:\n",
        "                all_pred_boxes.append([train_idx] + nms_box)\n",
        "\n",
        "            for box in true_bboxes[idx]:\n",
        "                # many will get converted to 0 pred\n",
        "                if box[1] > threshold:\n",
        "                    all_true_boxes.append([train_idx] + box)\n",
        "\n",
        "            train_idx += 1\n",
        "\n",
        "    model.train()\n",
        "    return all_pred_boxes, all_true_boxes\n",
        "\n",
        "\n",
        "\n",
        "def convert_cellboxes(predictions, S=7, C=3):\n",
        "    \"\"\"\n",
        "    Converts bounding boxes output from Yolo with\n",
        "    an image split size of S into entire image ratios\n",
        "    rather than relative to cell ratios. Tried to do this\n",
        "    vectorized, but this resulted in quite difficult to read\n",
        "    code... Use as a black box? Or implement a more intuitive,\n",
        "    using 2 for loops iterating range(S) and convert them one\n",
        "    by one, resulting in a slower but more readable implementation.\n",
        "    \"\"\"\n",
        "\n",
        "    predictions = predictions.to(\"cpu\")\n",
        "    batch_size = predictions.shape[0]\n",
        "    predictions = predictions.reshape(batch_size, 7, 7, C + 10)\n",
        "    bboxes1 = predictions[..., C + 1:C + 5]\n",
        "    bboxes2 = predictions[..., C + 6:C + 10]\n",
        "    scores = torch.cat(\n",
        "        (predictions[..., C].unsqueeze(0), predictions[..., C + 5].unsqueeze(0)), dim=0\n",
        "    )\n",
        "    best_box = scores.argmax(0).unsqueeze(-1)\n",
        "    best_boxes = bboxes1 * (1 - best_box) + best_box * bboxes2\n",
        "    cell_indices = torch.arange(7).repeat(batch_size, 7, 1).unsqueeze(-1)\n",
        "    x = 1 / S * (best_boxes[..., :1] + cell_indices)\n",
        "    y = 1 / S * (best_boxes[..., 1:2] + cell_indices.permute(0, 2, 1, 3))\n",
        "    w_y = 1 / S * best_boxes[..., 2:4]\n",
        "    converted_bboxes = torch.cat((x, y, w_y), dim=-1)\n",
        "    predicted_class = predictions[..., :C].argmax(-1).unsqueeze(-1)\n",
        "    best_confidence = torch.max(predictions[..., C], predictions[..., C + 5]).unsqueeze(\n",
        "        -1\n",
        "    )\n",
        "    converted_preds = torch.cat(\n",
        "        (predicted_class, best_confidence, converted_bboxes), dim=-1\n",
        "    )\n",
        "\n",
        "    return converted_preds\n",
        "\n",
        "\n",
        "def cellboxes_to_boxes(out, S=7):\n",
        "    converted_pred = convert_cellboxes(out).reshape(out.shape[0], S * S, -1)\n",
        "    converted_pred[..., 0] = converted_pred[..., 0].long()\n",
        "    all_bboxes = []\n",
        "\n",
        "    for ex_idx in range(out.shape[0]):\n",
        "        bboxes = []\n",
        "\n",
        "        for bbox_idx in range(S * S):\n",
        "            bboxes.append([x.item() for x in converted_pred[ex_idx, bbox_idx, :]])\n",
        "        all_bboxes.append(bboxes)\n",
        "\n",
        "    return all_bboxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "LEARNING_RATE = 2e-5\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 16 # 64 in original paper but resource exhausted error otherwise.\n",
        "WEIGHT_DECAY = 0\n",
        "EPOCHS = 20\n",
        "NUM_WORKERS = 2\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n",
        "LOAD_MODEL_FILE = \"model.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_fn(train_loader, model, optimizer, loss_fn):\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    mean_loss = []\n",
        "    \n",
        "    for batch_idx, (x, y) in enumerate(loop):\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        out = model(x)\n",
        "        loss = loss_fn(out, y)\n",
        "        mean_loss.append(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        loop.set_postfix(loss = loss.item())\n",
        "        \n",
        "    print(f\"Mean loss was {sum(mean_loss) / len(mean_loss)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img, bboxes):\n",
        "        for t in self.transforms:\n",
        "            img, bboxes = t(img), bboxes\n",
        "\n",
        "        return img, bboxes\n",
        "\n",
        "\n",
        "transform = Compose([transforms.Resize((448, 448)), transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:47<00:00,  7.16s/it, loss=588]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 621.3411193847656\n",
            "Train mAP: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:47<00:00,  7.19s/it, loss=269]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 291.35158487955727\n",
            "Train mAP: 0.00483837490901351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:48<00:00,  7.26s/it, loss=133]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 186.31904093424478\n",
            "Train mAP: 0.018925681710243225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [04:03<00:00, 16.25s/it, loss=107] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 138.1385706583659\n",
            "Train mAP: 0.06118858978152275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:48<00:00,  7.21s/it, loss=120] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 114.62545166015624\n",
            "Train mAP: 0.11969248205423355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:51<00:00,  7.42s/it, loss=88.3]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 94.67417170206706\n",
            "Train mAP: 0.18848581612110138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:49<00:00,  7.33s/it, loss=78.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 84.61801249186198\n",
            "Train mAP: 0.28366509079933167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:56<00:00,  7.79s/it, loss=92.5]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 75.2849843343099\n",
            "Train mAP: 0.369758278131485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:53<00:00,  7.58s/it, loss=84.7]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 71.11714324951171\n",
            "Train mAP: 0.45097848773002625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:52<00:00,  7.49s/it, loss=60.9]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 63.42679189046224\n",
            "Train mAP: 0.5686163902282715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:52<00:00,  7.50s/it, loss=42.6]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 58.87096227010091\n",
            "Train mAP: 0.6435170769691467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:59<00:00,  7.97s/it, loss=40.7]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 54.309617614746095\n",
            "Train mAP: 0.7196611762046814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [02:04<00:00,  8.33s/it, loss=52.9]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 49.94816919962565\n",
            "Train mAP: 0.7481398582458496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:57<00:00,  7.83s/it, loss=34.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 50.51283340454101\n",
            "Train mAP: 0.7759342789649963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:53<00:00,  7.60s/it, loss=50]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 48.71889877319336\n",
            "Train mAP: 0.8342804312705994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:58<00:00,  7.90s/it, loss=47.6]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 46.36133003234863\n",
            "Train mAP: 0.8143224716186523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:59<00:00,  7.96s/it, loss=43.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 44.45524673461914\n",
            "Train mAP: 0.8545041680335999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:53<00:00,  7.54s/it, loss=42.6]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 40.589372126261395\n",
            "Train mAP: 0.8675833344459534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [01:58<00:00,  7.90s/it, loss=37.7]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 43.341047286987305\n",
            "Train mAP: 0.8768510222434998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [02:05<00:00,  8.35s/it, loss=33.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean loss was 40.68894907633464\n",
            "Train mAP: 0.9032683372497559\n",
            "Saving Checkpoint\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = YoloV1(split_size=7, num_boxes=2, num_classes=3).to(DEVICE)\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1, patience=3, mode='max', verbose=True)\n",
        "\n",
        "loss_fn = YoloLoss()\n",
        "\n",
        "# if LOAD_MODEL:\n",
        "#     load_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)\n",
        "\n",
        "train_dataset = FruitImagesDataset(\n",
        "    transform=transform,\n",
        "    files_dir=files_dir\n",
        ")\n",
        "\n",
        "test_dataset = FruitImagesDataset(\n",
        "    transform=transform, \n",
        "    files_dir=test_dir\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_fn(train_loader, model, optimizer, loss_fn)\n",
        "    \n",
        "    pred_boxes, target_boxes = get_bboxes(\n",
        "        train_loader, model, DEVICE, iou_threshold=0.5, threshold=0.4\n",
        "    )\n",
        "\n",
        "    mean_avg_prec = mean_average_precision(\n",
        "        pred_boxes, target_boxes, iou_threshold=0.5, box_format=\"midpoint\"\n",
        "    )\n",
        "    print(f\"Train mAP: {mean_avg_prec}\")\n",
        "    \n",
        "    scheduler.step(mean_avg_prec)\n",
        "    \n",
        "checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "}\n",
        "\n",
        "print(\"Saving Checkpoint\")\n",
        "torch.save(checkpoint, LOAD_MODEL_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "box_coordinate_losses = [loss.item() for loss in loss_fn.box_coordinate_losses]\n",
        "object_losses = [loss.item() for loss in loss_fn.object_losses]\n",
        "no_object_losses = [loss.item() for loss in loss_fn.no_object_losses]\n",
        "class_losses = [loss.item() for loss in loss_fn.class_losses]\n",
        "\n",
        "plt.plot(range(len(box_coordinate_losses)), box_coordinate_losses, color='red', linestyle='-', linewidth=1, label='Box Coordinate Loss')\n",
        "plt.plot(range(len(object_losses)), object_losses, color='blue', linestyle='-', linewidth=1, label='Object Loss')\n",
        "plt.plot(range(len(no_object_losses)), no_object_losses, color='green', linestyle='-', linewidth=1, label='No Object Loss')\n",
        "plt.plot(range(len(class_losses)), class_losses, color='orange', linestyle='-', linewidth=1, label='Class Loss')\n",
        "\n",
        "plt.title('Losses')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig('losses.png')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementing Yolov8 and fine tuning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Yolo model is pretrained on the COCO Data Set:\n",
        "https://cocodataset.org/#home"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image\n",
        "\n",
        "model = YOLO(\"yolov8m.pt\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are multiple models you can select, just remeber the bigger models will be more acurate in predictions but it will cause the model to be slower, so take into account what may be best for your specific application:\n",
        "\n",
        "| Classification  | Detection | Segmentation   | Kind |\n",
        "|-------|-----|------------| ----- |\n",
        "| yolov8n-cls.pt | yolov8n.pt |\tyolov8n-seg.pt |\tNano |\n",
        "| yolov8s-cls.pt |\tyolov8s.pt| yolov8s-seg.pt\t| Small |\n",
        "| yolov8m-cls.pt | yolov8m.pt | yolov8m-seg.pt\t| Medium | \n",
        "| yolov8l-cls.pt | yolov8l.pt |\tyolov8l-seg.pt\t| Large |\n",
        "| yolov8x-cls.pt | yolov8x.pt |\tyolov8x-seg.pt\t| Huge |\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is how you use the model on a basic image, like a stop sign:  \n",
        "<img src=\"Stop.jpg\" width=\"400\" height=\"400\"> . \n",
        "But when we pass a yield sign, it can't detect any object: \n",
        "<img src=\"Yield.jpg\" width=\"400\" height=\"400\"> . \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /Users/aidanhousenbold/GHW_DeepLearningProject/Stop.jpg: 448x640 1 car, 2 trucks, 1 stop sign, 169.4ms\n",
            "Speed: 3.5ms preprocess, 169.4ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n",
            "\n",
            "image 1/1 /Users/aidanhousenbold/GHW_DeepLearningProject/Yield.jpg: 448x640 (no detections), 133.8ms\n",
            "Speed: 0.9ms preprocess, 133.8ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n"
          ]
        },
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "results1 = model.predict(\"Stop.jpg\", save=True, save_crop = True)\n",
        "results2 = model.predict(\"Yield.jpg\")\n",
        "Image(filename='runs/detect/predict/Stop.jpg')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, a yield sign is not detected. You can see what items are in the COCO set here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "stop sign\n",
            "Object type: stop sign\n",
            "Coordinates: [120, 16, 165, 63]\n",
            "Probability: 0.93\n",
            "---\n",
            "Object type: truck\n",
            "Coordinates: [23, 83, 72, 104]\n",
            "Probability: 0.82\n",
            "---\n",
            "Object type: truck\n",
            "Coordinates: [112, 89, 139, 100]\n",
            "Probability: 0.45\n",
            "---\n",
            "Object type: car\n",
            "Coordinates: [131, 89, 149, 100]\n",
            "Probability: 0.45\n",
            "---\n",
            "yield sign image\n"
          ]
        }
      ],
      "source": [
        "result = results1[0]\n",
        "print(\"stop sign\")\n",
        "if result.boxes != None:\n",
        "    for box in result.boxes:\n",
        "        class_id = result.names[box.cls[0].item()]\n",
        "        cords = box.xyxy[0].tolist()\n",
        "        cords = [round(x) for x in cords]\n",
        "        conf = round(box.conf[0].item(), 2)\n",
        "        print(\"Object type:\", class_id)\n",
        "        print(\"Coordinates:\", cords)\n",
        "        print(\"Probability:\", conf)\n",
        "        print(\"---\")\n",
        "else:\n",
        "   print(\"no objects detected\")\n",
        "\n",
        "print(\"yield sign image\")\n",
        "result = results2[0]\n",
        "for box in result.boxes:\n",
        "        class_id = result.names[box.cls[0].item()]\n",
        "        cords = box.xyxy[0].tolist()\n",
        "        cords = [round(x) for x in cords]\n",
        "        conf = round(box.conf[0].item(), 2)\n",
        "        print(\"Object type:\", class_id)\n",
        "        print(\"Coordinates:\", cords)\n",
        "        print(\"Probability:\", conf)\n",
        "        print(\"---\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So we can use a specialized data set to train our model onto be good at traffic sign image detection for applications like self driving cars:\n",
        "https://www.kaggle.com/datasets/pkdarabi/cardetection  The following code will let us train our model on the signs dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.6 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.2 🚀 Python-3.11.8 torch-2.2.0 CPU (Apple M1 Max)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train14\n",
            "Overriding model.yaml nc=80 with nc=15\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3784381  ultralytics.nn.modules.head.Detect           [15, [192, 384, 576]]         \n",
            "Model summary: 295 layers, 25865005 parameters, 25864989 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 84/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/aidanhousenbold/GHW_DeepLearningProject/self/train/labels.cache... 3530 images, 3 backgrounds, 0 corrupt: 100%|██████████| 3530/3530 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/aidanhousenbold/GHW_DeepLearningProject/self/valid/labels.cache... 801 images, 0 backgrounds, 0 corrupt: 100%|██████████| 801/801 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train14/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train14\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/30         0G      2.786      5.255      2.749         44        640:   4%|▍         | 9/221 [03:58<1:33:45, 26.54s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata.yaml\u001b[39;49m\u001b[39m\"\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:673\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    674\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m {\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m}:\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:199\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[1;32m    198\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:371\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamp):\n\u001b[1;32m    370\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 371\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_items \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(batch)\n\u001b[1;32m    372\u001b[0m     \u001b[39mif\u001b[39;00m RANK \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m    373\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m world_size\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:88\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mForward pass of the model on a single scale. Wrapper for `_forward_once` method.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m    (torch.Tensor): The output of the network.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):  \u001b[39m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     89\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:266\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcriterion\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    264\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_criterion()\n\u001b[0;32m--> 266\u001b[0m preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(batch[\u001b[39m\"\u001b[39;49m\u001b[39mimg\u001b[39;49m\u001b[39m\"\u001b[39;49m]) \u001b[39mif\u001b[39;00m preds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m preds\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(preds, batch)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:89\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):  \u001b[39m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:107\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_once(x, profile, visualize, embed)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:128\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 128\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[1;32m    129\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:230\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m--> 230\u001b[0m y\u001b[39m.\u001b[39mextend(m(y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(torch\u001b[39m.\u001b[39mcat(y, \u001b[39m1\u001b[39m))\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:230\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m--> 230\u001b[0m y\u001b[39m.\u001b[39mextend(m(y[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(torch\u001b[39m.\u001b[39mcat(y, \u001b[39m1\u001b[39m))\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:340\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    339\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv1(x)) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x))\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ultralytics/nn/modules/conv.py:50\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     49\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)))\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "model.train(data=\"data.yaml\", epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "194bcd7de31d65bbc1a48bf8247d32090cefaf0363192a6aab9d38fb776fdfb5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
